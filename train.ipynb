{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # 서버적용 코드\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the CSV file\n",
    "filtered_data = pd.read_csv('./filtered_data_with_prompt.csv')\n",
    "filtered_song_meta = pd.read_csv('./filtered_song_meta.csv')\n",
    "\n",
    "# Extract song IDs from filtered_data\n",
    "filtered_song_ids = set()\n",
    "for songs in filtered_data['songs']:\n",
    "    filtered_song_ids.update(json.loads(songs))\n",
    "\n",
    "# Convert song meta data to dictionary\n",
    "song_meta_dict = filtered_song_meta.set_index('id').to_dict('index')\n",
    "\n",
    "# Convert string embeddings to list of floats\n",
    "for song_id, song_info in song_meta_dict.items():\n",
    "    song_info['embedding'] = json.loads(song_info['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilingual BERT 모델과 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
    "\n",
    "# 함수 정의: 텍스트 인코딩\n",
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, text_embedding_dim, genre_embedding_dim, hidden_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(text_embedding_dim * 2 + genre_embedding_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, text_embedding_dim)  # 768 차원의 벡터 출력\n",
    "\n",
    "    def forward(self, album_emb, song_emb, genre_emb):\n",
    "        x = torch.cat((album_emb, song_emb, genre_emb), dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicRecommendationEnv:\n",
    "    def __init__(self, playlists, song_meta, num_samples=50):\n",
    "        self.playlists = playlists\n",
    "        self.song_meta = song_meta\n",
    "        self.num_samples = num_samples\n",
    "        self.current_playlist_index = 0\n",
    "        self.recommended_songs = set()\n",
    "        self.action_space = len(self.song_meta)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_playlist_index = np.random.randint(len(self.playlists))\n",
    "        playlist = self.playlists[self.current_playlist_index]\n",
    "        self.recommended_songs = set()\n",
    "        return self._sample_songs(playlist), playlist['prompt']\n",
    "\n",
    "    def step(self, action):\n",
    "        if action not in self.song_meta:\n",
    "            raise ValueError(f\"Action {action} is not in song_meta.\")\n",
    "        playlist = self.playlists[self.current_playlist_index]\n",
    "        reward = calculate_reward(action, playlist)\n",
    "        done = len(self.recommended_songs) >= 10\n",
    "        next_state, next_prompt = self._sample_songs(playlist), playlist['prompt']\n",
    "        song_meta = self.song_meta[action]\n",
    "        album_emb = encode_text(song_meta['album_name'])\n",
    "        song_emb = encode_text(song_meta['song_name'])\n",
    "        genre_emb = torch.tensor(song_meta['embedding'], dtype=torch.float32).to(device)\n",
    "        genre_emb = genre_emb.unsqueeze(0) if genre_emb.dim() == 1 else genre_emb\n",
    "\n",
    "        self.recommended_songs.add(action)\n",
    "        return next_state, next_prompt, album_emb, song_emb, genre_emb, reward, done\n",
    "\n",
    "    def _sample_songs(self, playlist):\n",
    "        sampled_songs = random.sample(json.loads(playlist['songs']), min(20, len(json.loads(playlist['songs']))))\n",
    "        other_songs = [song_id for song_id in self.song_meta.keys() if song_id not in sampled_songs and song_id not in self.recommended_songs]\n",
    "        sampled_songs += random.sample(other_songs, self.num_samples - len(sampled_songs))\n",
    "        return sampled_songs\n",
    "\n",
    "def calculate_reward(recommended_song, playlist):\n",
    "    if recommended_song in json.loads(playlist['songs']):\n",
    "        return 1\n",
    "    else:\n",
    "        return -0.1\n",
    "    \n",
    "\n",
    "\n",
    "env = MusicRecommendationEnv(filtered_data.to_dict('records'), song_meta_dict)\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN 모델 초기화\n",
    "text_embedding_dim = 768  # BERT base model output size\n",
    "genre_embedding_dim = 8  # 장르 임베딩 크기\n",
    "hidden_dim = 256\n",
    "\n",
    "model_path = './weights/from_simple_20_100_1000.pth'  # 저장된 모델 파일 경로\n",
    "model = QNetwork(text_embedding_dim, genre_embedding_dim, hidden_dim).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "def train_dqn(env, model, episodes, gamma, epsilon, epsilon_min, epsilon_decay, batch_size, weight=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    criterion = nn.MSELoss()\n",
    "    memory = []\n",
    "    rewards_per_episode = []\n",
    "\n",
    "    for episode in tqdm(range(episodes), desc=\"Training DQN\"):\n",
    "        state, prompt = env.reset()\n",
    "        prompt_emb = encode_text(prompt).view(1, -1)  # 프롬프트를 벡터로 변환\n",
    "        total_reward = 0\n",
    "\n",
    "        for t in range(10):  # 각 프롬프트에 대해 10개의 노래 추천\n",
    "            if np.random.rand() <= epsilon:\n",
    "                while True:\n",
    "                    action_idx = np.random.randint(len(state))\n",
    "                    action = state[action_idx]\n",
    "                    if action not in env.recommended_songs:\n",
    "                        break\n",
    "            else:\n",
    "                max_similarity = -float('inf')\n",
    "                action = None\n",
    "                action_idx = None\n",
    "                for idx, song_id in enumerate(state):\n",
    "                    if song_id in env.song_meta and song_id not in env.recommended_songs:\n",
    "                        song_meta = env.song_meta[song_id]\n",
    "                        album_emb = encode_text(song_meta['album_name'])\n",
    "                        song_emb = encode_text(song_meta['song_name'])\n",
    "                        genre_emb = torch.tensor(song_meta['embedding'], dtype=torch.float32).to(device)\n",
    "                        genre_emb = genre_emb.unsqueeze(0) if genre_emb.dim() == 1 else genre_emb\n",
    "                        song_vector = model(album_emb, song_emb, genre_emb)\n",
    "\n",
    "                        # song_vector와 prompt_emb의 코사인 유사도를 계산\n",
    "                        similarity = torch.cosine_similarity(song_vector, prompt_emb, dim=1).item()\n",
    "                        if similarity > max_similarity:\n",
    "                            max_similarity = similarity\n",
    "                            action = song_id\n",
    "                            action_idx = idx\n",
    "\n",
    "            if action is None:\n",
    "                continue\n",
    "\n",
    "            next_state, next_prompt, album_emb, song_emb, genre_emb, reward, done = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            # 프롬프트 임베딩 업데이트\n",
    "            song_vector = model(album_emb, song_emb, genre_emb)\n",
    "            prompt_emb = prompt_emb + weight * song_vector * reward\n",
    "\n",
    "            next_state_vector = prompt_emb  # 프롬프트가 변경되었으므로 업데이트된 prompt_emb 사용\n",
    "\n",
    "            memory.append((album_emb, song_emb, genre_emb, prompt_emb, reward, next_state_vector, done, action))\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            if len(memory) > batch_size:\n",
    "                minibatch = random.sample(memory, batch_size)\n",
    "                for album_emb, song_emb, genre_emb, prompt_emb, reward, next_state_vec, done, action in minibatch:\n",
    "                    target = reward\n",
    "                    if not done:\n",
    "                        with torch.no_grad():\n",
    "                            next_q_values = model(next_state_vec, song_emb, genre_emb)\n",
    "                            target += gamma * next_q_values.max().item()\n",
    "\n",
    "                    # 현재 상태에서의 Q-값\n",
    "                    current_q_values = model(album_emb, song_emb, genre_emb)\n",
    "\n",
    "                    # 타겟 Q-값\n",
    "                    target_q_values = current_q_values.clone()\n",
    "                    target_q_values[0][action_idx] = target\n",
    "\n",
    "                    # 손실 계산 및 역전파\n",
    "                    model.zero_grad()\n",
    "                    loss = criterion(current_q_values, target_q_values)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "        rewards_per_episode.append(total_reward)\n",
    "        if epsilon > epsilon_min:\n",
    "            epsilon *= epsilon_decay\n",
    "\n",
    "        if (episode + 1) % 10 == 0:\n",
    "            average_reward = np.mean(rewards_per_episode[-10:])\n",
    "            print(f\"Episode {episode + 1}/{episodes} - Average Reward (last 10 episodes): {average_reward:.2f}\")\n",
    "\n",
    "    return model, rewards_per_episode\n",
    "\n",
    "# 환경 초기화\n",
    "env = MusicRecommendationEnv(filtered_data.to_dict('records'), song_meta_dict,500)\n",
    "\n",
    "# DQN 학습\n",
    "episodes = 100000\n",
    "gamma = 0.95\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "batch_size = 256\n",
    "\n",
    "trained_model, rewards_per_episode = train_dqn(env, model, episodes, gamma, epsilon, epsilon_min, epsilon_decay, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "weight_name = \"from_simple_20_500_10000\"\n",
    "torch.save(trained_model.state_dict(), f'./weights/{weight_name}.pth')\n",
    "print(f\"Model saved to '{weight_name}.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 에피소드별 보상 시각화\n",
    "plt.plot(rewards_per_episode)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Total Reward per Episode')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
