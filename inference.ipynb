{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (fc1): Linear(in_features=1544, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # 서버적용 코드\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Q-Network 클래스 정의\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, text_embedding_dim, genre_embedding_dim, hidden_dim):\n",
    "        super(QNetwork, self).__init__()\n",
    "        input_dim = text_embedding_dim * 2 + genre_embedding_dim\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, text_embedding_dim)\n",
    "\n",
    "    def forward(self, album_emb, song_emb, genre_emb):\n",
    "        album_emb = torch.tensor(album_emb).view(1, -1).to(device)\n",
    "        song_emb = torch.tensor(song_emb).view(1, -1).to(device)\n",
    "        genre_emb = torch.tensor(genre_emb).view(1, -1).to(device)\n",
    "        x = torch.cat((album_emb, song_emb, genre_emb), dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 학습된 모델 로드\n",
    "model_path = 'file path for your weight file'\n",
    "text_embedding_dim = 768\n",
    "genre_embedding_dim = 8\n",
    "hidden_dim = 256\n",
    "model = QNetwork(text_embedding_dim, genre_embedding_dim, hidden_dim).to(device)\n",
    "\n",
    "# 저장된 모델의 상태를 로드\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Network embeddings saved to 'fine_qnetwork_embeddings2.csv'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Multilingual BERT 모델과 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
    "\n",
    "# 함수 정의: 텍스트 인코딩\n",
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().cpu().numpy()\n",
    "\n",
    "# 노래 메타데이터 로드\n",
    "song_meta = pd.read_csv('./filtered_song_meta.csv')\n",
    "\n",
    "# 앨범명, 곡명 임베딩 생성\n",
    "album_embeddings = song_meta['album_name'].apply(encode_text)\n",
    "song_embeddings = song_meta['song_name'].apply(encode_text)\n",
    "genre_embeddings = song_meta['embedding'].apply(eval).apply(lambda x: torch.tensor(x, dtype=torch.float32).cpu().numpy())\n",
    "\n",
    "# Q-Network 출력 임베딩 생성\n",
    "def get_qnetwork_embedding(row):\n",
    "    album_emb = row['album_embedding']\n",
    "    song_emb = row['song_embedding']\n",
    "    genre_emb = row['genre_embedding']\n",
    "    with torch.no_grad():\n",
    "        qnetwork_emb = model(album_emb, song_emb, genre_emb).cpu().numpy().tolist()\n",
    "    return qnetwork_emb\n",
    "\n",
    "# 데이터프레임 생성\n",
    "embeddings_df = pd.DataFrame({\n",
    "    'id': song_meta['id'],\n",
    "    'album_embedding': album_embeddings.apply(lambda x: x.tolist()),\n",
    "    'song_embedding': song_embeddings.apply(lambda x: x.tolist()),\n",
    "    'genre_embedding': genre_embeddings.apply(lambda x: x.tolist())\n",
    "})\n",
    "\n",
    "# Q-Network 출력 임베딩 추가\n",
    "embeddings_df['qnetwork_embedding'] = embeddings_df.apply(get_qnetwork_embedding, axis=1)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "embeddings_df.to_csv('./embeddings.csv', index=False)\n",
    "print(\"Q-Network embeddings saved to 'embeddings'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # 서버적용 코드\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Multilingual BERT 모델과 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
    "\n",
    "# 함수 정의: 텍스트 인코딩\n",
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# 임베딩 데이터 로드\n",
    "embeddings_df = pd.read_csv('./embeddings')\n",
    "# embeddings_df = pd.read_csv('./simple_qnetwork_embeddings.csv')\n",
    "embeddings_df['qnetwork_embedding'] = embeddings_df['qnetwork_embedding'].apply(eval)\n",
    "\n",
    "# 노래 메타데이터 로드 및 매핑 생성\n",
    "song_meta = pd.read_csv('./filtered_song_meta.csv')\n",
    "id_to_song_info = dict(zip(song_meta['id'], zip(song_meta['song_name'], song_meta['artist_name_basket'])))\n",
    "\n",
    "# 예측 함수 정의\n",
    "def predict_songs(prompt, embeddings_df, num_recommendations=10, weight=0.01):\n",
    "    prompt_emb = torch.tensor(encode_text(prompt)).view(1, -1).to(device)\n",
    "    recommended_songs = []\n",
    "    \n",
    "    for i in range(num_recommendations):\n",
    "        max_similarity = -float('inf')\n",
    "        best_song = None\n",
    "\n",
    "        for idx, row in embeddings_df.iterrows():\n",
    "            qnetwork_emb = torch.tensor(row['qnetwork_embedding']).view(1, -1).to(device)\n",
    "            \n",
    "            similarity = torch.cosine_similarity(qnetwork_emb, prompt_emb, dim=1).item()\n",
    "\n",
    "            if similarity > max_similarity and row['id'] not in [song['id'] for song in recommended_songs]:\n",
    "                max_similarity = similarity\n",
    "                best_song = {\n",
    "                    'id': row['id'],\n",
    "                    'qnetwork_emb': qnetwork_emb\n",
    "                }\n",
    "\n",
    "        if best_song is not None:\n",
    "            song_name, artist_name_basket = id_to_song_info.get(best_song['id'], ('Unknown Title', 'Unknown Artist'))\n",
    "            artist_names = ', '.join(eval(artist_name_basket))\n",
    "            recommended_songs.append({\n",
    "                'id': best_song['id'],\n",
    "                'title': song_name,\n",
    "                'artists': artist_names,\n",
    "                'qnetwork_emb': best_song['qnetwork_emb']\n",
    "            })\n",
    "            print(f\"Recommended Song {i+1}: ID: {best_song['id']}, Title: {song_name}, Artists: {artist_names}\")\n",
    "            reward = float(input(f\"Enter the reward for song '{song_name}' by '{artist_names}' (e.g., 1.0 or -1.0): \"))\n",
    "            # 상태 업데이트\n",
    "            prompt_emb = (1-weight) * prompt_emb + weight * best_song['qnetwork_emb'] * reward\n",
    "\n",
    "    return recommended_songs\n",
    "\n",
    "# 사용자 입력 받기\n",
    "prompt = input(\"Enter the prompt: \")\n",
    "\n",
    "# 예측 수행\n",
    "recommended_songs = predict_songs(prompt, embeddings_df)\n",
    "print(\"Recommended Songs:\")\n",
    "for song in recommended_songs:\n",
    "    print(f\"ID: {song['id']}, Title: {song['title']}, Artists: {song['artists']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
